{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import vgg1\n",
    "# import download\n",
    "import imagecomputations\n",
    "# import lossfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to get mean squared error between content image and mixed image; and styling image and mixed image\n",
    "def mse(a, b):\n",
    "    sqr = tf.square(a - b)\n",
    "    redmean = tf.reduce_mean(sqr)\n",
    "    return redmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading content image\n",
    "Cimage = imagecomputations.get_image('images/elon_musk.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading style image\n",
    "Simage = imagecomputations.get_image('texture_outer/texture/texture_0011.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "styleids = list(range(13))\n",
    "contentids = [4]\n",
    "\n",
    "#declaring the layer number for which we want to use for the style image & content image \n",
    "def style_transfer(Cimage, Simage, contentids, styleids, weight_content, weight_style, num_iterations, step_size):\n",
    "    \n",
    "    #Init the model\n",
    "    model = vgg1.VGG16()\n",
    "    \n",
    "    #creating the session ofr model and keeping it interactive to add nodes    \n",
    "    session = tf.InteractiveSession(graph=model.graph)\n",
    "    #Here initially the layer tensors for the content image are saved and the mse between the Content image and Mixed image is calculated in every layer\n",
    "    feed_dict = model.create_feed_dict(image=Cimage)\n",
    "    layers = model.get_layer_tensors(contentids)\n",
    "    content_values = session.run(layers, feed_dict=feed_dict)\n",
    "    with model.graph.as_default():\n",
    "        layer_losses = []\n",
    "#       filewriter = tf.summary.FileWriter('C:\\\\Users\\\\Raj Mehta\\\\Documents\\\\GitHub\\\\nst', loss.graph)\n",
    "        for i in range(0, len(content_values)):\n",
    "            loss = mse(content_values[i], layers[i])\n",
    "            layer_losses.append(loss)\n",
    "        total_loss_content = tf.reduce_mean(layer_losses)\n",
    "    \n",
    "    #Here first we calculate the gram matrix which is basically the correlation between different fiter responses and then we add this filter responses by taking the mse between them and Mixed image and gram image to mix the image with the style image\n",
    "    #Here initially the layer tensors for the style image are saved and the mse between the Style image and Mixed image is calculated in every layer\n",
    "    feed_dict = model.create_feed_dict(image=Simage)\n",
    "    layers = model.get_layer_tensors(styleids)\n",
    "    gram_layers = []\n",
    "    with model.graph.as_default():\n",
    "        for layer in layers:\n",
    "            shape = layer.get_shape()\n",
    "            num_channels = int(shape[3])\n",
    "            matrix = tf.reshape(layer, shape=[-1, num_channels])\n",
    "            gram = tf.matmul(tf.transpose(matrix), matrix)\n",
    "            gram_layers.append(gram)\n",
    "        values = session.run(gram_layers, feed_dict=feed_dict)\n",
    "        layer_losses = []\n",
    "        for i in range(0, len(values)):\n",
    "            loss = mse(gram_layers[i], values[i])\n",
    "            layer_losses.append(loss)\n",
    "        total_loss_style = tf.reduce_mean(layer_losses)\n",
    "    \n",
    "    #Init of the learning rates\n",
    "    adj_content = tf.Variable(1/1e-10, name='adj_content')\n",
    "    adj_style = tf.Variable(1/1e-10, name='adj_style')\n",
    "\n",
    "    session.run([adj_content.initializer,\n",
    "                 adj_style.initializer])\n",
    "\n",
    "    #calculating the learing rates ny taking the reciprocal of the respective losses\n",
    "    update_adj_content = adj_content.assign(1.0 / (total_loss_content))\n",
    "    update_adj_style = adj_style.assign(1.0 / (total_loss_style))\n",
    "\n",
    "    #This is the combined loss calculated in particular iteration based on the weight of the content of the style image we want to be in mixed image\n",
    "    loss_combined = weight_content * adj_content * total_loss_content + \\\n",
    "                    weight_style * adj_style * total_loss_style\n",
    "\n",
    "    # this is the gradient calculated between the combined loss and the mixed image to use for back propoagation and update the image    \n",
    "    gradient = tf.gradients(loss_combined, model.input)\n",
    "\n",
    "    run_list = [gradient, update_adj_content, update_adj_style]\n",
    "\n",
    "    Mimage = np.random.rand(*Cimage.shape) + 128\n",
    "\n",
    "    #Iterations for constructing the mixed image\n",
    "    for i in range(num_iterations):\n",
    "        feed_dict = model.create_feed_dict(image=Mimage)\n",
    "        \n",
    "        #running the session and calculating the gradient\n",
    "        grad, adj_content_val, adj_style_val =  \\\n",
    "        session.run(run_list, feed_dict=feed_dict)\n",
    "        \n",
    "#         filewriter = tf.summary.FileWriter('C:\\\\Users\\\\Raj Mehta\\\\Documents\\\\GitHub\\\\nst', grad.graph)\n",
    "\n",
    "        grad = np.squeeze(grad)\n",
    "\n",
    "        step_size_scaled = step_size / (np.std(grad) )\n",
    "\n",
    "        #upadting the mixed image based on the gradient and the step size\n",
    "        Mimage -= grad * step_size_scaled\n",
    "\n",
    "        Mimage = np.clip(Mimage, 0.0, 255.0)\n",
    "\n",
    "        if (i % 10 == 0):\n",
    "            print()\n",
    "            print(\"On Iteration {0:d} the output is: \".format(i))\n",
    "\n",
    "            imagecomputations.plot_images(Cimage=Cimage,\n",
    "                        Simage=Simage,\n",
    "                        Mimage=Mimage)\n",
    "            \n",
    "    print()\n",
    "    print(\"Final image:\")\n",
    "    imagecomputations.plot_final_image(Mimage)\n",
    "\n",
    "    session.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#runnning the model\n",
    "style_transfer(Cimage=Cimage,\n",
    "                     Simage=Simage,\n",
    "                     contentids=contentids,\n",
    "                     styleids=styleids,\n",
    "                     weight_content=3.0,\n",
    "                     weight_style=10.0,\n",
    "                     num_iterations=30,\n",
    "                     step_size=10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
